# -*- coding: utf-8 -*-
"""LVADSUSR125-SwathiM-FA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ezC3Udanhngfg2gCTLTVmU1vqewUIt3Q
"""

#1
import pandas as pd
df=pd.read_excel(r"/content/Walmart_Dataset Python_Final_Assessment.xlsx")
df.head()

df.info()

df.describe()

df.size

df.shape

df.dtypes

num_column=df.select_dtypes(include = 'number')
num_column

cat_column=df.select_dtypes(include = 'object')
cat_column

#2
df.isnull().sum()
#there are no missing values

df.duplicated()
#there are no duplicates found

#3
num_column.mean()

num_column.median()

num_column.shape

num_column.std()

num_column.var()

num_column.describe()

print("Mean: Sales \n", df['Sales'].mean())
print("Median: Sales \n", df['Sales'].median())
print("Mode: Sales \n", df['Sales'].mode())
print("Range: Sales \n", df['Sales'].max() - df['Sales'].min())
print("Variance: Sales \n", df['Sales'].var())
print("Standard Deviation: Sales \n", df['Sales'].std())
print("Mean: Quantity \n", df['Quantity'].mean())
print("Median: Quantity \n", df['Quantity'].median())
print("Mode: Quantity \n", df['Quantity'].mode())
print("Range: Quantity \n", df['Quantity'].max() - df['Quantity'].min())
print("Variance: Quantity \n", df['Quantity'].var())
print("Standard Deviation: Quantity \n", df['Quantity'].std())
print("Mean: Profit \n", df['Profit'].mean())
print("Median: Profit \n", df['Profit'].median())
print("Mode: Profit \n", df['Profit'].mode())
print("Range: Profit \n", df['Profit'].max() - df['Profit'].min())
print("Variance: Profit \n", df['Profit'].var())
print("Standard Profit: Profit \n", df['Profit'].std())

#4
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

df['Order Date'] = pd.to_datetime(df['Order Date'])
df['Ship Date'] = pd.to_datetime(df['Ship Date'])
df['Order Year'] = pd.to_datetime(df['Order Date']).dt.year


salesData = df.groupby('Order Year')['Sales'].sum()
salesData.plot(label='Sales')
profitData = df.groupby('Order Year')['Profit'].sum()
profitData.plot(label='Profit')
plt.grid(True)
plt.legend()
plt.show()

plt.figure(figsize=(10, 6))
sns.barplot(x='Category', y='Sales', data=df)
plt.title('Sales by Category')
plt.xlabel('Category')
plt.ylabel('Sales')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(x='Quantity', y='Profit', data=df)
plt.title('Profit vs Quantity')
plt.xlabel('Quantity')
plt.ylabel('Profit')
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='Profit', data=df)
plt.title('Profit Distribution')
plt.xlabel('Profit')
plt.tight_layout()
plt.show()

#5
import seaborn as sns
df.corr()

sns.heatmap(df.corr())

#6
numeric_cols = ['Sales', 'Quantity', 'Profit']
df_zscores = df[numeric_cols].apply(lambda x: np.abs((x - x.mean()) / x.std()))

outliers = df_zscores > 3

outliers_data = df[outliers.any(axis=1)]

print("Outliers:")
print(outliers_data)

plt.figure(figsize=(10, 6))
sns.boxplot(data=df[numeric_cols])
plt.title('Boxplot of Sales, Quantity, and Profit')
plt.xlabel('Features')
plt.ylabel('Values')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

#7
#trend analysis
#i.
df['Order Month'] = pd.to_datetime(df['Order Date']).dt.month
salesData = df.groupby('Order Year')['Sales'].sum()
salesData.plot(label='Sales')
profitData = df.groupby('Order Year')['Profit'].sum()
profitData.plot(label='Profit')
plt.grid(True)
plt.legend()
plt.show()

salesData = df.groupby('Order Month')['Sales'].sum()
salesData.plot(label='Sales')
profitData = df.groupby('Order Month')['Profit'].sum()
profitData.plot(label='Profit')
plt.grid(True)
plt.legend()
plt.show()

#7
#trend analysis
#ii.
total_sales = df.groupby(['Order Year', 'Category'])['Sales'].sum().reset_index()
total_sales['Growth'] = total_sales.groupby('Category')['Sales'].pct_change() * 100
most_growth_category = total_sales.groupby('Category')['Growth'].mean().idxmax()
print("Category with the Most Growth in Sales:", most_growth_category)

#7
#Customer analysis
#i.
customer_summary = df.groupby('EmailID').agg({'Order ID': 'nunique', 'Sales': 'sum'}).reset_index()
customer_summary.columns = ['EmailID', 'Quantity', 'TotalSales']

top_customers_by_orders = customer_summary.nlargest(5, 'Quantity')
top_customers_by_sales = customer_summary.nlargest(5, 'TotalSales')

print("Top 5 Customers by Orders Placed:")
print(top_customers_by_orders.set_index('EmailID'))
print("\nTop 5 Customers by Total Sales:")
print(top_customers_by_sales.set_index('EmailID'))

#7
#Customer analysis
#ii.
df['OrderDate'] = pd.to_datetime(df['Order Date'])
df.sort_values(by=['EmailID', 'Order Date'], inplace=True)
df['TimeBetweenOrders'] = df.groupby('EmailID')['Order Date'].diff()
average_time_between_orders = df.groupby('EmailID')['TimeBetweenOrders'].mean()
print("Average Time Between Orders for Each Customer:")
print(average_time_between_orders)
print(average_time_between_orders.mean())

#7
#comprehensive analytics
#i
df['TimeBetweenOrderAndDelivery'] = df['Ship Date'] - df['Order Date']
average_time_between_order_and_delivery = df.groupby('Category')['TimeBetweenOrderAndDelivery'].mean()
print(average_time_between_order_and_delivery)

df['TimeBetweenOrderAndDelivery'] = df['Ship Date'] - df['Order Date']
average_time_between_order_and_delivery = df.groupby('EmailID')['TimeBetweenOrderAndDelivery'].mean()
print(average_time_between_order_and_delivery.mean())

"""i) As of now the average time taken for the shipment of an order is 8 days and 20 hours.It stands highest for Tables delivery . Allocation of bigger trucks through optimised organisation of transporters can be introduced to improve the supply chain.

ii) The geographic distribution of sales is influenced by factors such as demographics (age, income), cultural preferences, economic conditions and local requirements. Insights from these factors can inform targeted marketing by enabling businesses to tailor products, pricing, promotions, and advertising strategies to specific regions, demographics, and consumer behaviors thus improving sales performance and customer engagement.
"""

#7
#comprehensive analytics
#iii
customer_order_amounts = df.groupby('EmailID')['Sales'].sum().reset_index()

top_10_percent = int(len(customer_order_amounts) * 0.1)
high_value_customers = customer_order_amounts.nlargest(top_10_percent, 'Sales')
print(high_value_customers)

customer_order_amounts = df.groupby('EmailID')['Quantity'].sum().reset_index()

top_10_percent = int(len(customer_order_amounts) * 0.1)
high_value_customers = customer_order_amounts.nlargest(top_10_percent, 'Quantity')
print(high_value_customers)

for index, customer in high_value_customers.iterrows():
  pass

"""
iii) High value customers can be identified by their purchasing quantity, purchase frequency and pruchase amount . These customers can be given additional promotions and offers to enhance customer loyalty and they are more likely to recommend wallmart to other potential customers"""